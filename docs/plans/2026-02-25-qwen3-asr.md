# Qwen3-ASR Integration Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** 整合兩個 Qwen3-ASR-0.6B 本地引擎（FluidAudio CoreML、MLX Swift），讓使用者可以 A/B 比較，特別針對中英夾雜場景。

**Architecture:** 新增兩個 `ModelProvider` case（`.qwen3FluidAudio`、`.qwen3MLX`）和對應的 `TranscriptionService` 實作。FluidAudio 路徑使用已整合的 SPM，MLX 路徑新增 `qwen3-asr-swift` SPM。兩者共用同一個 `Qwen3Model` 結構，僅 `provider` 欄位不同。

**Tech Stack:**
- FluidAudio `main` branch（已有）— `Qwen3AsrManager` actor，`@available(macOS 15, iOS 18, *)`
- `ivan-digital/qwen3-asr-swift` SPM — MLX Swift，`import Qwen3ASR`，需 macOS 14+ Apple Silicon
- 參考實作：`ParakeetTranscriptionService.swift`、`WhisperState+Parakeet.swift`

---

## Branch

```bash
git checkout -b feature/qwen3-asr
```

---

## Task 1: 擴充 ModelProvider 和 Qwen3Model struct

**Files:**
- Modify: `VoiceInk/Models/TranscriptionModel.swift`

**Step 1: 在 `ModelProvider` enum 新增兩個 case**

在 `case nativeApple = "Native Apple"` 後面加：

```swift
case qwen3FluidAudio = "Qwen3 (CoreML)"
case qwen3MLX = "Qwen3 (MLX)"
```

**Step 2: 在檔案末尾新增 `Qwen3Model` struct**

```swift
struct Qwen3Model: TranscriptionModel {
    let id = UUID()
    let name: String
    let displayName: String
    let description: String
    let provider: ModelProvider   // .qwen3FluidAudio 或 .qwen3MLX
    let size: String
    var isMultilingualModel: Bool { true }
    let supportedLanguages: [String: String]
}
```

**Step 3: Commit**

```bash
git add VoiceInk/Models/TranscriptionModel.swift
git commit -m "feat: add Qwen3Model and qwen3FluidAudio/qwen3MLX ModelProvider cases"
```

---

## Task 2: 在 PredefinedModels 登記 Qwen3 模型

**Files:**
- Modify: `VoiceInk/Models/PredefinedModels.swift`

**Step 1: 找到 `predefinedModels` 靜態陣列，在 Parakeet 條目之後加入 Qwen3 條目**

找到 `static let predefinedModels: [any TranscriptionModel]` 或 `static var models`，加入：

```swift
// Qwen3-ASR (FluidAudio CoreML, macOS 15+)
Qwen3Model(
    name: "qwen3-asr-0.6b-coreml",
    displayName: "Qwen3-ASR 0.6B (CoreML)",
    description: "Alibaba Qwen3-ASR via CoreML. 52 languages + 22 Chinese dialects. Requires macOS 15+.",
    provider: .qwen3FluidAudio,
    size: "~900 MB",
    supportedLanguages: getLanguageDictionary(isMultilingual: true)
),

// Qwen3-ASR (MLX, macOS 14+, Apple Silicon)
Qwen3Model(
    name: "qwen3-asr-0.6b-mlx",
    displayName: "Qwen3-ASR 0.6B (MLX)",
    description: "Alibaba Qwen3-ASR via MLX Swift. 52 languages + 22 Chinese dialects. Requires Apple Silicon.",
    provider: .qwen3MLX,
    size: "~400 MB",
    supportedLanguages: getLanguageDictionary(isMultilingual: true)
),
```

**Step 2: Commit**

```bash
git add VoiceInk/Models/PredefinedModels.swift
git commit -m "feat: register Qwen3-ASR models in PredefinedModels"
```

---

## Task 3: 實作 Qwen3FluidAudioTranscriptionService

**Files:**
- Create: `VoiceInk/Services/Qwen3FluidAudioTranscriptionService.swift`

**Step 1: 建立檔案**

```swift
import Foundation
import FluidAudio
import os.log

@available(macOS 15, iOS 18, *)
class Qwen3FluidAudioTranscriptionService: TranscriptionService {
    private var manager: Qwen3AsrManager?
    private var modelsLoaded = false
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink.qwen3", category: "FluidAudio")

    private func ensureModelsLoaded() async throws {
        if modelsLoaded { return }
        let models = try await Qwen3AsrModels.downloadAndLoad(variant: .int8)
        let mgr = Qwen3AsrManager()
        await mgr.loadModels(from: models.directory)
        self.manager = mgr
        self.modelsLoaded = true
    }

    func transcribe(audioURL: URL, model: any TranscriptionModel) async throws -> String {
        try await ensureModelsLoaded()
        guard let manager = manager else {
            throw TranscriptionError.modelNotLoaded
        }
        let audioSamples = try readAudioSamples(from: audioURL)
        // 傳 nil 讓模型自動偵測語言（中英夾雜最佳）
        return try await manager.transcribe(audioSamples: audioSamples, language: nil as String?)
    }

    private func readAudioSamples(from url: URL) throws -> [Float] {
        let data = try Data(contentsOf: url)
        guard data.count > 44 else { throw TranscriptionError.invalidAudio }
        return stride(from: 44, to: data.count, by: 2).map {
            data[$0..<$0 + 2].withUnsafeBytes {
                let short = Int16(littleEndian: $0.load(as: Int16.self))
                return max(-1.0, min(Float(short) / 32767.0, 1.0))
            }
        }
    }
}
```

> **注意：** `Qwen3AsrModels.downloadAndLoad` 回傳 `Qwen3AsrModels`，但 `Qwen3AsrManager.loadModels(from:)` 需要一個目錄 URL。需要在實作時查看 `Qwen3AsrModels.defaultCacheDirectory(variant:)` 取得正確路徑，調整 `ensureModelsLoaded()`。實際 API 以 FluidAudio source 為準。

**Step 2: 為了讓 `TranscriptionError` 可用，確認現有錯誤型別**

搜尋現有 `ASRError` 或 `TranscriptionError`：

```bash
grep -r "enum.*Error" VoiceInk/Services/ --include="*.swift" -l
```

如果已有 `ASRError`，改用 `throw ASRError.notInitialized`（Parakeet 的做法）。

**Step 3: Commit**

```bash
git add VoiceInk/Services/Qwen3FluidAudioTranscriptionService.swift
git commit -m "feat: add Qwen3FluidAudioTranscriptionService (CoreML via FluidAudio)"
```

---

## Task 4: 新增 MLX SPM 依賴並實作 Qwen3MLXTranscriptionService

**Files:**
- Modify: `VoiceInk.xcodeproj/project.pbxproj`（透過 Xcode UI）
- Create: `VoiceInk/Services/Qwen3MLXTranscriptionService.swift`

**Step 1: 在 Xcode 加入 SPM 依賴**

File → Add Package Dependencies → 輸入：

```
https://github.com/ivan-digital/qwen3-asr-swift
```

Branch: `main`。勾選 product：`Qwen3ASR`。

**Step 2: 建立 service 檔案**

```swift
import Foundation
import Qwen3ASR
import os.log

class Qwen3MLXTranscriptionService: TranscriptionService {
    private var model: Qwen3ASRModel?
    private let logger = Logger(subsystem: "com.prakashjoshipax.voiceink.qwen3", category: "MLX")

    private func ensureModelLoaded() async throws {
        if model != nil { return }
        // 預設下載 0.6B 4-bit，~400 MB，存於 HuggingFace 本地快取
        model = try await Qwen3ASRModel.fromPretrained()
    }

    func transcribe(audioURL: URL, model loadedModel: any TranscriptionModel) async throws -> String {
        try await ensureModelLoaded()
        guard let model = model else {
            throw ASRError.notInitialized
        }
        let audioSamples = try readAudioSamples(from: audioURL)
        // sampleRate: 16000（VoiceInk 的 CoreAudioRecorder 固定輸出 16kHz）
        return model.transcribe(audio: audioSamples, sampleRate: 16000)
    }

    private func readAudioSamples(from url: URL) throws -> [Float] {
        let data = try Data(contentsOf: url)
        guard data.count > 44 else { throw ASRError.invalidAudioData }
        return stride(from: 44, to: data.count, by: 2).map {
            data[$0..<$0 + 2].withUnsafeBytes {
                let short = Int16(littleEndian: $0.load(as: Int16.self))
                return max(-1.0, min(Float(short) / 32767.0, 1.0))
            }
        }
    }
}
```

> **注意：** 實作前先查 `Qwen3ASRModel` 實際 API（README 範例或原始碼），確認 `transcribe(audio:sampleRate:)` 是否為 async/throws，以及參數名稱。

**Step 3: Commit**

```bash
git add VoiceInk/Services/Qwen3MLXTranscriptionService.swift
git commit -m "feat: add Qwen3MLXTranscriptionService (MLX via qwen3-asr-swift)"
```

---

## Task 5: 在 TranscriptionServiceRegistry 路由兩個 service

**Files:**
- Modify: `VoiceInk/Services/TranscriptionServiceRegistry.swift`

**Step 1: 新增 lazy properties（在 `parakeetTranscriptionService` 後加）**

```swift
@available(macOS 15, iOS 18, *)
private(set) lazy var qwen3FluidAudioTranscriptionService = Qwen3FluidAudioTranscriptionService()

private(set) lazy var qwen3MLXTranscriptionService = Qwen3MLXTranscriptionService()
```

**Step 2: 在 `service(for:)` 的 switch 裡加兩個 case**

```swift
case .qwen3FluidAudio:
    if #available(macOS 15, iOS 18, *) {
        return qwen3FluidAudioTranscriptionService
    } else {
        // Fallback：macOS 14 設備回退到 MLX
        return qwen3MLXTranscriptionService
    }
case .qwen3MLX:
    return qwen3MLXTranscriptionService
```

**Step 3: 在 `cleanup()` 中加清理**

```swift
// Qwen3 services 目前無需顯式 cleanup（MLX/CoreML 資源由 ARC 管理）
```

**Step 4: Commit**

```bash
git add VoiceInk/Services/TranscriptionServiceRegistry.swift
git commit -m "feat: route qwen3FluidAudio and qwen3MLX in TranscriptionServiceRegistry"
```

---

## Task 6: 新增 WhisperState+Qwen3 下載管理

**Files:**
- Create: `VoiceInk/Whisper/WhisperState+Qwen3.swift`

**Step 1: 建立下載輔助方法（參考 `WhisperState+Parakeet.swift`）**

```swift
import Foundation
import FluidAudio

extension WhisperState {
    // MARK: - Qwen3 FluidAudio

    private func qwen3DefaultsKey(for modelName: String) -> String {
        "Qwen3ModelDownloaded_\(modelName)"
    }

    func isQwen3ModelDownloaded(named modelName: String) -> Bool {
        UserDefaults.standard.bool(forKey: qwen3DefaultsKey(for: modelName))
    }

    func isQwen3ModelDownloaded(_ model: Qwen3Model) -> Bool {
        isQwen3ModelDownloaded(named: model.name)
    }

    @MainActor
    func downloadQwen3FluidAudioModel(_ model: Qwen3Model) async {
        guard !isQwen3ModelDownloaded(model) else { return }

        let modelName = model.name
        downloadProgress[modelName] = 0.0

        do {
            if #available(macOS 15, iOS 18, *) {
                _ = try await Qwen3AsrModels.downloadAndLoad(variant: .int8)
            }
            UserDefaults.standard.set(true, forKey: qwen3DefaultsKey(for: modelName))
            downloadProgress[modelName] = 1.0
        } catch {
            UserDefaults.standard.set(false, forKey: qwen3DefaultsKey(for: modelName))
        }
    }

    // MARK: - Qwen3 MLX（qwen3-asr-swift 自動下載，無需手動管理）

    func isQwen3MLXModelDownloaded(_ model: Qwen3Model) -> Bool {
        // MLX 路徑在 fromPretrained() 時自動下載並快取，無法預先查詢
        // 回傳 false 讓 UI 顯示「首次使用將自動下載」
        false
    }
}
```

**Step 2: Commit**

```bash
git add VoiceInk/Whisper/WhisperState+Qwen3.swift
git commit -m "feat: add WhisperState+Qwen3 download helpers"
```

---

## Task 7: 建置驗證

**Step 1: 建置確認沒有編譯錯誤**

```bash
make local
```

預期：build 成功。

常見錯誤排除：
- `ModelProvider` switch exhaustiveness 警告 → 確認 `supportsStreaming()` 和 `batchFallbackModel()` 都有 default case
- `Qwen3ASRModel` API 與計劃不符 → 查 `qwen3-asr-swift` README 修正
- `Qwen3AsrManager.loadModels()` 路徑問題 → 查 `Qwen3AsrModels.defaultCacheDirectory(variant:)` 取得正確 URL

**Step 2: 替換 App 測試**

```bash
pkill -x VoiceInk 2>/dev/null
rm -rf /Applications/VoiceInk.app && cp -R ~/Downloads/VoiceInk.app /Applications/VoiceInk.app
tccutil reset Microphone com.prakashjoshipax.VoiceInk
open /Applications/VoiceInk.app
```

在模型選擇 UI 找到「Qwen3-ASR 0.6B (MLX)」，切換後錄一段中英夾雜語音，確認轉錄結果。

---

## 已知風險與備案

| 風險 | 備案 |
|------|------|
| `Qwen3AsrManager` 需要 `Qwen3AsrModels` 載入後的目錄，API 不明確 | 查 FluidAudio source 的 `defaultCacheDirectory(variant:)`，手動傳路徑 |
| `Qwen3ASRModel.transcribe()` 可能是 `async throws` 而非 sync | 加 `try await` 並更新 service 簽名 |
| MLX 在 Intel Mac 上無法執行 | Task 5 已有 fallback；FluidAudio 路徑需 macOS 15，MLX 需 Apple Silicon，Intel 設備最終回退 whisper |
| FluidAudio beta 準確度損失 | 計劃即為 A/B 比較，正是為了驗證這點 |
